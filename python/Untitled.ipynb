{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['001.zip',\n",
       " 'd3js-samples-master.zip',\n",
       " 'JDBCSample.zip',\n",
       " 'library.zip',\n",
       " 'putty.zip',\n",
       " 'script.zip']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob \n",
    "\n",
    "filelist=glob.glob(\"*.zip\")\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-12280739153a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-12280739153a>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    with zipfile.ZipFile('001.zip','r') as zf\u001b[0m\n\u001b[1;37m                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('001.zip','r') as zf\n",
    "test=zf.read('TAIPEI_capacity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dryscrape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f804bb7f87f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdryscrape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dryscrape'"
     ]
    }
   ],
   "source": [
    "import dryscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dryscrape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-78fe80a5d7a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdryscrape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msleep\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m  \u001b[1;31m#正規表示法\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dryscrape'"
     ]
    }
   ],
   "source": [
    "import dryscrape\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import re  #正規表示法\n",
    "import csv\n",
    "\n",
    "my_url = \"http://24h.pchome.com.tw/region/DGBM\"    \n",
    "#my_url = \"http://24h.pchome.com.tw/store/DGBMF0\" \n",
    "filename = \"pchome_htc.csv\"\n",
    "\n",
    "# enable X-server on headless system\n",
    "dryscrape.start_xvfb()  #啟動虛擬介面\n",
    "\n",
    "def scrape_web(myurl):\n",
    "    # create web scraping session   \n",
    "    sess = dryscrape.Session()\n",
    "    sess.visit(myurl)\n",
    "    sleep(1)\n",
    "\n",
    "    # get html and create BeautifulSoup object\n",
    "    response = sess.body()\n",
    "    return BeautifulSoup(response, \"lxml\")\n",
    "\n",
    "def parse_web(soup):\n",
    "    gb = [e for e in soup.select('div.grab_box') if len(e['class']) == 1] #去除grab_box unblock [len(class)=2]\n",
    "    for data in gb:\n",
    "        prod=data.find_all(class_='prod_info')\n",
    "        for pd in prod:\n",
    "            try:\n",
    "                pname = pd.find(class_='nick').text.strip('\\n')\n",
    "            except Exception:\n",
    "                continue\n",
    "            pprice = pd.find(class_='price').text\n",
    "            if pname and pprice:\n",
    "                print(pname, pprice)\n",
    "                wt.writerow((pname,pprice))\n",
    "\n",
    "# MAIN\n",
    "soup = scrape_web(my_url)\n",
    "menu = soup.find(id='MenuContainer')\n",
    "slink = menu.find_all('dt',text=re.compile(\"系列\"))\n",
    "\n",
    "# open csv file to write\n",
    "fp = open('pchome_htc.csv','w')\n",
    "wt = csv.writer(fp)\n",
    "wt.writerow(('prodname','price')) #逗點分隔\n",
    "\n",
    "for sl in slink:\n",
    "    for anchor in sl.find_next_sibling('dd').find_all('a'):\n",
    "        link = 'http:' + anchor.get('href')\n",
    "        print(link)\n",
    "        soup = scrape_web(link)\n",
    "        parse_web(soup)\n",
    "\n",
    "fp.close()        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
